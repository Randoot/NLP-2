{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Randoot/NLP-2/blob/main/Stemming_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "ii9sd-Nn_TTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "UMvRNmdk_Wng"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading necessary NLTK resources\n"
      ],
      "metadata": {
        "id": "FeOOYe46_YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "L3KxSNJj_WjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fe5665-a6ca-4496-93aa-993564580d5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample text"
      ],
      "metadata": {
        "id": "DXNU9Vic_apO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The leaves on the trees are falling. The children are playing with leaves in the park.\"\n"
      ],
      "metadata": {
        "id": "F_5JHYrp_WgO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the text into words\n"
      ],
      "metadata": {
        "id": "zoFDGkGn_cVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "vVcVhtNo_WaO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Stemming\n"
      ],
      "metadata": {
        "id": "TIXusxPl_ecC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words: \", stemmed_words)"
      ],
      "metadata": {
        "id": "puov6nZD_WWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e49fba-3e1e-4fb1-9014-41d23fb5054a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:  ['the', 'leav', 'on', 'the', 'tree', 'are', 'fall', '.', 'the', 'children', 'are', 'play', 'with', 'leav', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Lemmatization\n"
      ],
      "metadata": {
        "id": "gjDs9Pmc_gTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "dsqyCAUr_i3f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get part of speech tags compatible with WordNet\n"
      ],
      "metadata": {
        "id": "5t24WQ99_ksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map part-of-speech (PoS) tags from the tagset,\n",
        "# which is used by the pos_tag function from NLTK, to the WordNet PoS tagset.\n",
        "# Becasue WordNet uses different tags for categorizing words,\n",
        "# this function convert between these tagsets to be compatible with WordNet’s lemmatization\n",
        "def get_wordnet_pos(word):\n",
        "  # NLTK pos_tag is used to assign POS tags to words.\n",
        "  # It returns a list of tuples: word and its corresponding tag.\n",
        "  #[0][1]: Accesses the tag from the tuple : VBG\n",
        "  #[0]: Extracts the first character of the tag :v\n",
        "  # upper: character to uppercase.\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    # Now we Map Tags to WordNet Tags\n",
        "    tag_dict = {\"J\": wordnet.ADJ, #'J' (Adjective) → wordnet.ADJ\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "                #Looks up the WordNet tag corresponding to the Penn Treebank tag from the tag_dict dictionary.\n",
        "                # If the tag is not found in the dictionary, it defaults to wordnet.NOUN.\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "kgDD2hM__mhG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "print(\"Lemmatized Words: \", lemmatized_words)"
      ],
      "metadata": {
        "id": "6SgHxLJJ_tI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97498da1-79a8-42b7-a7de-40e2e0ee93b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:  ['The', 'leaf', 'on', 'the', 'tree', 'be', 'fall', '.', 'The', 'child', 'be', 'play', 'with', 'leaf', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare original, stemmed, and lemmatized words\n"
      ],
      "metadata": {
        "id": "-ry54fxp_vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gtKW6Vk4_Km2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01d70f8-5a5b-45c8-98ae-a9929765e774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison (Original, Stemmed, Lemmatized):\n",
            "The             -> the             -> The            \n",
            "leaves          -> leav            -> leaf           \n",
            "on              -> on              -> on             \n",
            "the             -> the             -> the            \n",
            "trees           -> tree            -> tree           \n",
            "are             -> are             -> be             \n",
            "falling         -> fall            -> fall           \n",
            ".               -> .               -> .              \n",
            "The             -> the             -> The            \n",
            "children        -> children        -> child          \n",
            "are             -> are             -> be             \n",
            "playing         -> play            -> play           \n",
            "with            -> with            -> with           \n",
            "leaves          -> leav            -> leaf           \n",
            "in              -> in              -> in             \n",
            "the             -> the             -> the            \n",
            "park            -> park            -> park           \n",
            ".               -> .               -> .              \n"
          ]
        }
      ],
      "source": [
        "comparison = list(zip(words, stemmed_words, lemmatized_words))\n",
        "print(\"\\nComparison (Original, Stemmed, Lemmatized):\")\n",
        "for original, stemmed, lemmatized in comparison:\n",
        "    print(f\"{original:15} -> {stemmed:15} -> {lemmatized:15}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PorterStemmer\n"
      ],
      "metadata": {
        "id": "JzVXuFXr_yVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "E3VD3gwV_4pi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to stem\n"
      ],
      "metadata": {
        "id": "vN9xnoxH_5me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "H0F65z_a_7GW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the stemmer"
      ],
      "metadata": {
        "id": "V3TrYFTr_9G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "JDAQYVcq_83z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Stem each word and print the result\n"
      ],
      "metadata": {
        "id": "9gbg_-WF__cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words = [___________ for word in words]\n",
        "\n",
        "print(\"Stemmed Words:\", stemmed_words)\n"
      ],
      "metadata": {
        "id": "n3ByrzKu_VAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import WordNetLemmatizer and other necessary modules\n"
      ],
      "metadata": {
        "id": "9v_oNGh8ABmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n"
      ],
      "metadata": {
        "id": "FK5TnQicAGK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to lemmatize\n"
      ],
      "metadata": {
        "id": "gqykQJbXAG7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "EhavRpJLAHzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the lemmatizer\n"
      ],
      "metadata": {
        "id": "JYJ0jgB_AIym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "tNAQ7KTcAJtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function to get WordNet PoS tag\n"
      ],
      "metadata": {
        "id": "svvQAi75AKWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "gV61RG-3ALb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Lemmatize each word with PoS tag and print the result\n"
      ],
      "metadata": {
        "id": "8XXYt1N_ANNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [____________ for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "RLuE1fcyAEBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}